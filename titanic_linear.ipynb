{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the cleaning data exercise, we know we have information about the passengers sex, age, class they travelled in as well as port of embarkation. We will choose these columns for our initial analysis. It is possible we will need to use others for refinements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeating some of the steps done in cleaning. Loading the data, making the data frame, replacing NA values for Age and assigning numeric codes for Sex and Embarked, all have to be repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset = pd.read_csv(\"train.csv\")\n",
    "trainframe = pd.DataFrame(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainframe[\"Age\"]= trainframe[\"Age\"].fillna(trainframe[\"Age\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainframe.loc[trainframe[\"Sex\"] ==\"male\", \"Sex\"] = 0\n",
    "trainframe.loc[trainframe[\"Sex\"] == \"female\", \"Sex\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainframe.loc[trainframe[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "trainframe.loc[trainframe[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "trainframe.loc[trainframe[\"Embarked\"] == \"Q\", \"Embarked\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainframe[\"Embarked\"] = trainframe[\"Embarked\"].fillna(trainframe[\"Embarked\"].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data frame is cleaned and ready for modeling, I want to split the training set into training and cross validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainX = trainframe[[\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\" ]]\n",
    "trainY = trainframe[[\"Survived\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(trainX, trainY, test_size = 0.2, train_size = 0.8, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will have to do multiple training and cross validation sets, but for now I want to one. I will extend it to more later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, normalize=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = test_predictions\n",
    "predictions[test_predictions < 0.5] = 0\n",
    "predictions[test_predictions >=0.5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, normalize=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = test_predictions\n",
    "predictions[test_predictions < 0.2] = 0\n",
    "predictions[test_predictions >=0.8] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accurracy = sum(predictions[predictions == Y_test])/ len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2681564245810056\n"
     ]
    }
   ],
   "source": [
    "print(accurracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = test_predictions\n",
    "predictions[test_predictions < 0.5] = 0\n",
    "predictions[test_predictions >=0.5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accurracy = sum(predictions[predictions == Y_test])/ len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2681564245810056\n"
     ]
    }
   ],
   "source": [
    "print(accurracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "I am missing \"Age\" variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = trainframe[[\"Survived\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = trainframe[[\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Embarked\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, normalize=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, normalize=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = test_predictions\n",
    "predictions[test_predictions < 0.5] = 0\n",
    "predictions[test_predictions >=0.5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accurracy = sum(predictions[predictions == Y_test])/ len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25139664804469275\n"
     ]
    }
   ],
   "source": [
    "print(accurracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = trainframe[[\"Survived\"]]\n",
    "X = trainframe[[\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.5, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "446"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train)\n",
    "test_predictions = model.predict(X_test)\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "446"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = test_predictions\n",
    "predictions[test_predictions < 0.2] = 0\n",
    "predictions[test_predictions >=0.2] = 1\n",
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2623318385650224\n"
     ]
    }
   ],
   "source": [
    "accurracy = sum(predictions[predictions == Y_test])/ len(predictions)\n",
    "print(accurracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems unusually low. I have tried changing the threshold as well as predictors used. It seems I may have to be more explicit in how I set up the \"Predictions\" list as well as possibly flatten Y_test, since that is probably a numpy array. Repeating some steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = trainframe[[\"Survived\"]]\n",
    "X = trainframe[[\"Pclass\", \"Sex\", \"Age\", \"Embarked\"]]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train)\n",
    "test_predictions = model.predict(X_test)\n",
    "predictions = [1 if x >0.5 else 0 for x in  test_predictions]\n",
    "type(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_flat = np.ravel(Y_test).tolist()\n",
    "type(Y_test_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8268156424581006\n"
     ]
    }
   ],
   "source": [
    "accurracy = [1 if predictions[i] == Y_test_flat[i] else 0 for i in range(len(predictions                                                                    ))]\n",
    "print(sum(accurracy)/len(accurracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems more reasonable as it is comparable to the result from  a kfold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "We need the size of our data table so we can run the kfold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "framesize = trainframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "framesize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10692"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainframe.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(framesize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "framesize[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainfolds = sklearn.cross_validation.KFold(framesize[0], n_folds = 3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for train, test in trainfolds:\n",
    "    train_predictors = trainframe[predictors].iloc[train, :]\n",
    "    train_survival = trainframe[\"Survived\"].iloc[train]\n",
    "    model.fit(train_predictors, train_survival)\n",
    "    survival = model.predict(trainframe[predictors].iloc[test, :])\n",
    "    predictions.append(survival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.08998778098664151, 0.9607562062264055, 0.5926762776633075,\n",
       "        0.9311387278910148, 0.05293430709559843, 0.17027568492773426,\n",
       "        0.36994359030196217, 0.10347484742579838, 0.5215979058146017,\n",
       "        0.8744910503206459, 0.6488836111621751, 0.8297427688347137,\n",
       "        0.13479719839863458, -0.16112684364249996, 0.658141306629678,\n",
       "        0.6398197484682683, 0.15173387493789658, 0.29543271790803693,\n",
       "        0.5353779589276423, 0.6210076833082594, 0.2618725916383585,\n",
       "        0.2626875613868225, 0.7317391597365727, 0.5059958971692387,\n",
       "        0.5613985666552637, 0.3350397341633621, 0.13033880755757976,\n",
       "        0.468765766528213, 0.660737752649524, 0.09108192184311426,\n",
       "        0.4772239200354355, 1.042200261903615, 0.6606916127819146,\n",
       "        0.08715392731116511, 0.5285507322778307, 0.4018743378420788,\n",
       "        0.1303403074603967, 0.12933967231176546, 0.5727171285933563,\n",
       "        0.6652388218334943, 0.4832157785469819, 0.7608074080287127,\n",
       "        0.13057836346464147, 0.8718671208885532, 0.7098554874313455,\n",
       "        0.091136989703682, 0.139181745384777, 0.6606916127819146,\n",
       "        0.06828334846322537, 0.6062543741132724, 0.049225438285450895,\n",
       "        0.12925039238218083, 0.9026682575449473, 0.7516779544466687,\n",
       "        0.31963682154535655, 0.5059958971692387, 0.8234114769709531,\n",
       "        0.1276115444169621, 0.8165169470844362, -0.037020906034181955,\n",
       "        0.16308546398161106, 0.9579813395173064, 0.3967421027161868,\n",
       "        0.06161384085263111, 0.5427142330778643, 0.0662112274537564,\n",
       "        0.7797512682760005, 0.1402934005509997, 0.4405927416366107,\n",
       "        0.035053438777735035, 0.2727098142647135, 0.42636033928215245,\n",
       "        0.3552411434756206, 0.11022688013554927, 0.08660783580690579,\n",
       "        0.10736672007695358, 0.09108192184311426, 0.091136989703682,\n",
       "        0.382661024227508, 0.5724710680342731, 0.12422140995731834,\n",
       "        0.08619728720840425, 0.6607050047713523, 0.5101384859019693,\n",
       "        0.8452415813184294, 0.456477760432308, 0.03226992043652244,\n",
       "        0.091136989703682, 0.9376045379314164, 0.11296709405115823,\n",
       "        0.08567946361681289, 0.13472727435778387, 0.3833208069103614,\n",
       "        0.006149703931847217, -0.07833201476393026, 0.091136989703682,\n",
       "        0.3105166651976248, 0.5493454209974187, 0.7235443378437991,\n",
       "        0.23372144826164376, 0.5817507975937939, 0.09108192184311426,\n",
       "        0.5257384235303151, 0.06406513100315703, -0.025242723970099634,\n",
       "        0.09108192184311426, 0.6198657001751098, 0.09103878178113889,\n",
       "        0.036506660974423455, 0.6329397066990878, 0.4081953768713173,\n",
       "        0.6636573058852232, 0.12388214622489635, 0.5924912921857819,\n",
       "        0.6836236243224796, 0.12929503234697315, -0.06192212166070077,\n",
       "        0.25922348010429475, 0.6096559550391273, 0.5307943783628588,\n",
       "        0.288023804548453, 0.091136989703682, 0.28285794196288827,\n",
       "        0.7615427262678058, 0.34564006266363567, 0.18548499825655262,\n",
       "        0.17002273703123483, 0.11264272221099114, 0.5594201172011213,\n",
       "        -0.0020248574703064515, 0.10329073303029612, 0.13444007868029573,\n",
       "        0.44680762252355116, 0.7516779544466687, 0.31180529616864416,\n",
       "        0.3629473854836871, 0.9757244494395432, 0.42955479996659696,\n",
       "        0.15704395432149676, 0.5829285748296498, 0.5571054761909284,\n",
       "        0.6144438860600745, 0.5728128341412972, 0.21878335209471755,\n",
       "        0.3494722991992194, 0.2860400800597307, 0.09650373595814932,\n",
       "        0.5609161058087934, 0.1869197095538716, 0.2190273526918699,\n",
       "        0.16973998604383744, 1.0069076832178872, -0.05894497768521745,\n",
       "        -0.041545257153078996, 0.09087361391140714, 0.39582791493052033,\n",
       "        0.7261759619250471, 0.08022193752994389, 0.09135572553116456,\n",
       "        -0.22253609628133275, -0.02669191043068697, 0.7215933598417197,\n",
       "        0.101953833954877, 0.15138851248672436, 0.08197059480666524,\n",
       "        0.13251846088628827, 0.9702453109504343, 0.3289748930146633,\n",
       "        0.5025764758661442, 0.10843794015438213, 0.32518329686588165,\n",
       "        0.14081882276415847, 0.6632682110867054, 0.12929503234697315,\n",
       "        0.39096593380758843, 0.07865036059084651, -0.036852468165768815,\n",
       "        0.9136716905421012, 0.2845176657342987, 0.04460196727610177,\n",
       "        0.268132779469347, 0.3356612549521588, 0.0019629959724086765,\n",
       "        0.3514703995260526, 0.6510106466488217, 0.5111741330851519,\n",
       "        0.6298506211354569, 0.4100217322133318, 0.0403081358652565,\n",
       "        0.04742171314816168, 0.7642714893112404, 0.3445504526898585,\n",
       "        0.5972450067317489, 0.3695214604774933, 0.946062691438639,\n",
       "        0.9120831487611267, 0.17002273703123483, -0.018525180185340995,\n",
       "        0.6606916127819146, 0.807931698006193, 0.09165481329527336,\n",
       "        -0.22253609628133275, 0.05783679771622541, 0.034832101037371,\n",
       "        0.1457122505723727, 0.6911797985563585, 0.038483749695664926,\n",
       "        0.1453830564746107, 0.7261819258243434, 0.4783949870158123,\n",
       "        0.11260997433281938, 0.750755868797344, 0.12359645045022527,\n",
       "        0.2845176657342987, 0.13641406756765095, 1.0139549529110583,\n",
       "        0.5872187515764384, 0.19041835928502993, 1.028898630608532,\n",
       "        0.28362486643845164, 0.1566273027461108, 0.30089024399490594,\n",
       "        -0.034386110294306715, 0.09108192184311426, 0.43727499148643123,\n",
       "        0.12434640185873691, 0.34365765339401144, 0.13178273958052888,\n",
       "        0.3500079787767277, 0.45381640758491093, 0.9419862393355573,\n",
       "        0.08558125569426978, 0.12642796907426512, 0.5144619760705648,\n",
       "        0.3163700229596661, 0.5816273055951924, 0.17914618739295307,\n",
       "        0.8332173587099047, 0.34365765339401144, 0.26788617567789597,\n",
       "        0.5899807037124909, 0.6298506211354569, 0.28908239252532075,\n",
       "        0.12355181048543296, 0.11942375538384165, 0.4499140487446874,\n",
       "        0.5980802357924258, 0.741700784629518, 0.395976587547236,\n",
       "        0.12457092652426238, 0.09085129392901092, 0.5102179247473098,\n",
       "        0.31724378873655756, 0.04948808179898789, 0.4484349019451769,\n",
       "        0.5516479501040594, 1.0517673462328532, 1.0039628263814615,\n",
       "        1.168243641533099, 0.6372952796089105, 0.17002273703123483,\n",
       "        0.034708152493623134, 0.32379014070836565, 0.42782783412578085,\n",
       "        0.6606916127819146, 0.2508797099172373, 0.00010770350362920844,\n",
       "        0.07380269057816224, 0.8416824286113007, 0.9942216662041741,\n",
       "        0.5043888584367139, 0.10463475423166146, 0.6840917362215297,\n",
       "        0.4609200131654874, 0.6606916127819146, 0.7872053865530633,\n",
       "        0.4889207860620859, 0.290790161569632, 0.12444624450355124,\n",
       "        0.4809680774693368, -0.03190572818292081, 0.09106706566283129,\n",
       "        0.15714512633770217, 0.14025472448550358, 0.5026032598450196,\n",
       "        0.10356453671834642, 0.08073976112153525, 0.1238270783643286,\n",
       "        0.2190273526918699, 0.6934367693031289, 1.0230609648836455,\n",
       "        1.0715187081091817, 0.29122431086981926, 0.6039216655765092,\n",
       "        0.11291202619059049, 0.5427142330778643, 0.15489917485130755], dtype=object),\n",
       " array([1.1377479117577005, 0.44173212012563506, 0.9855134656666826,\n",
       "        0.6691537065342812, 0.08254227921947, 0.15142623745818906,\n",
       "        0.836420138579806, 0.09704525980556311, 0.6471148104765996,\n",
       "        1.038451730502104, 1.0606421243171043, 0.2464784164481686,\n",
       "        0.9836490235960713, 1.0441160876100029, 1.101957338613606,\n",
       "        0.7259638674801141, 0.09692709027963742, 0.11388411008073596,\n",
       "        0.6082498705906578, 0.7490572473416877, 0.09042400079967228,\n",
       "        1.0031427295487496, 0.9158836764203722, 0.1367988612176937,\n",
       "        0.10365486909339783, 0.8229645809522854, 0.7551740007492737,\n",
       "        -0.2774628539909585, 1.0035963986084964, -0.12636043109872475,\n",
       "        0.7086567825092811, 0.524387994445003, 1.0690047610596047,\n",
       "        0.580441381619432, 0.3224633122087502, 0.4590475106076491,\n",
       "        0.08481309732971942, 0.9683838329171319, 0.09692709027963742,\n",
       "        0.41237389908786737, 0.9690890121678946, -0.01732698002836275,\n",
       "        0.33119157698190627, 0.3895314566104003, 0.9745547124250047,\n",
       "        0.2645799106194019, 0.2847632470606829, 0.21075768010931906,\n",
       "        0.7893901282744054, 0.6817456672542397, 0.5508181015495125,\n",
       "        0.21132237939189835, 0.003325739257467375, 0.13158460259656124,\n",
       "        0.4451806471468124, 0.16116388155958605, 0.07440511246549841,\n",
       "        0.13363265291676452, 0.0981564518457203, 0.9891353869560717,\n",
       "        0.6952012248817605, 0.6692527175767559, 0.6692527175767559,\n",
       "        -0.05732283136292038, 0.25605759067090583, 0.5130617135913023,\n",
       "        0.049184468771201306, 0.12689844167689446, 0.08297663070761085,\n",
       "        0.7455603166003834, 0.6315349739419464, 0.6691537065342812,\n",
       "        1.0334959271616513, 0.4679535931723475, 0.11283671101675585,\n",
       "        0.15759526912940625, 0.5998861996011793, 0.6125967032117545,\n",
       "        0.9661529199314176, 0.6346979636176557, 0.6051112977215058,\n",
       "        0.18499301830339576, 0.15738452581144546, 1.0336499502752499,\n",
       "        0.8004328210604303, 0.07003835213326692, 0.858717774269892,\n",
       "        0.09692709027963742, 0.37822122870838937, 0.03771546495566791,\n",
       "        0.7086567825092811, 0.1712386642760878, 0.8729378636977722,\n",
       "        0.3869263235747433, 0.14394490804215598, -0.0036411172661515723,\n",
       "        1.0236281860384646, 0.6092086682665017, 0.13721712922839568,\n",
       "        0.5746109765218561, 0.15344230336622788, 0.2963029563431051,\n",
       "        0.7622107942510501, 0.022943900436944387, 0.11050081743308382,\n",
       "        0.5931037738996376, 0.05272741431504058, 0.6492359755601571,\n",
       "        0.18004866011392506, -0.05792355471233668, 0.3772477175958543,\n",
       "        0.14392896818392475, 0.4477677653386134, 0.09692709027963742,\n",
       "        0.17057125934658934, 0.9757334728730779, 0.25461749922488963,\n",
       "        -0.01069499363185733, 0.5949443622055253, 0.6771228426672874,\n",
       "        0.8104811566888616, 0.2511243529918812, 0.7091067997275401,\n",
       "        0.13414671334472128, 0.21833625796369616, 0.09018337160764589,\n",
       "        0.5398775024407926, 0.11371053558078814, 0.09643218833513156,\n",
       "        0.7221461320866462, 0.8329914337377193, 0.17125460413431903,\n",
       "        0.0701341445505218, 0.4387050797403794, 0.5508181015495125,\n",
       "        0.6279572286940014, 0.17034196286924053, 0.2628907130818783,\n",
       "        1.032836559877433, 0.5423464678531693, 0.6642925281115133,\n",
       "        0.2888593976609827, 0.24248072583302238, 0.5983276548531773,\n",
       "        0.15197868235580314, 0.06672256060165338, 0.7624790130193639,\n",
       "        0.09709315601419055, 0.6232810528126068, 0.8587390786889724,\n",
       "        0.39833840685781735, 0.6852638523011314, 0.2802654285953868,\n",
       "        0.15249024855006454, 0.05588220346794737, 0.4633887523835899,\n",
       "        0.3322837996088506, 0.09704525980556311, 0.12741893453096098,\n",
       "        0.18977726363124658, 0.905706854307234, 0.6125520307715377,\n",
       "        0.17125460413431903, 0.3041495034651725, 0.056678586923000984,\n",
       "        0.32003503736850375, 0.13002433434419491, 0.09704525980556311,\n",
       "        0.0290011323299203, 0.25461749922488963, 0.2503272729550897,\n",
       "        0.171235445650868, 0.7138569122596129, 0.09643218833513156,\n",
       "        0.030236854512508793, 0.6705726873913077, 0.8339442410071753,\n",
       "        0.6366808666548327, 0.45820841589348227, 0.18004866011392506,\n",
       "        0.039252630701313684, 0.1370063859104348, 0.7634761520741833,\n",
       "        -0.016106765554414815, 0.25461749922488963, -0.050965874097164465,\n",
       "        0.3606503504561486, 0.4952640113317268, 0.4477677653386134,\n",
       "        0.8878386691153894, 0.276505307307477, 0.0835897021780424,\n",
       "        0.17095570650933634, 0.05588220346794737, 0.143526640031454,\n",
       "        0.2600820921541057, 0.20422092024699257, 0.14413971150188554,\n",
       "        0.13917581525060496, 0.7882388053640089, 0.10244795213874092,\n",
       "        0.9830089990412125, 0.12376157160087498, 0.17152020960147607,\n",
       "        0.7162481582306035, 0.669061132742246, 0.5355725996139177,\n",
       "        1.063279571220928, 0.5560152431033819, 0.7195268858769687,\n",
       "        0.4387050797403794, 0.10813802172368348, 0.14762673973587326,\n",
       "        0.16452682532055873, 0.09704525980556311, 0.38468168515406137,\n",
       "        0.7737805109750209, 0.12353166979946306, 0.31660245020555766,\n",
       "        0.7201964917917033, 0.18382256927816532, 0.6683239015765635,\n",
       "        0.07001597502459611, 0.974455043194559, 0.13729376316219954,\n",
       "        0.13363265291676452, 0.880626954274315, 0.1336358715419843,\n",
       "        0.08715736896231474, 0.6125520307715377, 0.5883168956343421,\n",
       "        0.022943900436944387, 0.18684088879263183, 0.8874305590103624,\n",
       "        0.1336358715419843, 0.14770832393206534, 0.6238533539529725,\n",
       "        0.5819581874225537, 0.8946407198692475, 0.32433283990645356,\n",
       "        1.0215796022038022, 0.10198814853591731, 1.012502321427886,\n",
       "        0.8975700907380044, 0.5201135770159115, 0.5066580193883908,\n",
       "        0.19733591443164278, 0.33882963120140314, 0.1960835558090852,\n",
       "        0.7826961414104894, 0.30246050136354474, 0.013033334417520193,\n",
       "        0.3574029316117619, 0.5952825505853999, 0.28127010082767445,\n",
       "        0.17131529820989178, 0.17399932579932664, 0.6351002917701265,\n",
       "        0.2099606000725277, 0.7989736649644027, 0.6299397512679328,\n",
       "        0.8433581194775873, 0.49799211217888095, 0.17125460413431903,\n",
       "        0.016193744514513275, 0.26496308028842164, 0.09704525980556311,\n",
       "        0.5949443622055253, 0.035703853748579206, 0.15747709960348055,\n",
       "        0.5596468643335165, 0.1336358715419843, 0.06998409530813376,\n",
       "        0.03391958260645156, 0.686923353767725, 0.3847583190878653,\n",
       "        0.6691537065342812, 0.17777860557068725, 0.16253815785976045,\n",
       "        0.7221123401368018, 0.8347953824332043, 0.586779625323337,\n",
       "        0.07003835213326692, 0.735757003646032, 0.9045130489894573,\n",
       "        0.09962007285614516, 0.4325055288092655, 0.13477258268209813,\n",
       "        1.0252989446597316, 0.13828479183403408, 0.24105043235162404,\n",
       "        0.13741193268812524, 0.09704525980556311, 0.04924194422155426,\n",
       "        0.8016943629915296, -0.031395609126315005, 0.6498780620661754], dtype=object),\n",
       " array([0.17288921873573093, 0.017029471499353077, 0.7826169347451191,\n",
       "        -0.008347888482774124, 0.14702226646327232, 0.31088859478921027,\n",
       "        0.7282613397249932, 0.10147991373934362, 0.4245656224699982,\n",
       "        0.015731658699460693, 0.43770806879792634, 0.014420426447759538,\n",
       "        0.09076784824248774, 0.4339138710026336, 0.8265372507367875,\n",
       "        0.8452623383163396, 0.5427761707793317, 0.10176366299230855,\n",
       "        0.6701484791497316, 0.19216345182293582, 0.06393595343531222,\n",
       "        0.7626506552814888, 0.03101247009671515, 0.5900246314025595,\n",
       "        0.8313562308775448, 0.2786489157515681, 0.10830965304269002,\n",
       "        0.3045312378928448, 0.15086412715865893, 0.13898609895956804,\n",
       "        0.13621979535339857, 0.25119791499306765, 0.2026258870152282,\n",
       "        0.9723571335628532, 0.1121919792361995, 0.19216905434424647,\n",
       "        0.1502118754949524, -0.021426499238869856, 0.4524510197871078,\n",
       "        0.43878998795322455, 0.6048200882379849, 0.7893265411051315,\n",
       "        0.08004598672034624, 0.2104357209331973, 0.5708852689614158,\n",
       "        0.05708417426028267, 0.14434213170799604, 1.004511037081528,\n",
       "        0.6423123174769806, 0.08517557028451339, 0.7333730072709166,\n",
       "        0.3096021172412259, 0.14968420847519526, 0.3222288322348338,\n",
       "        0.1015959228333082, 0.6506044782208688, 0.10147991373934362,\n",
       "        0.8450262411958038, 0.13879182230741394, 0.714365273427171,\n",
       "        0.7682876512706368, 0.18493893750614443, 0.10147991373934362,\n",
       "        0.6542185239424189, 0.2938783132018504, 0.2964131365782775,\n",
       "        0.19283353927878621, 0.08274987348213692, 0.32844126309625254,\n",
       "        0.058765843879120205, 0.10267498784736151, 0.1420906755187209,\n",
       "        0.28316624770499454, 0.10152043976175806, 0.02108769144788858,\n",
       "        0.9019300112084929, 0.6801824437882588, 0.3636335213177882,\n",
       "        0.04298347482073828, 0.2510300512144268, 0.27145939359371873,\n",
       "        0.1550807672460376, 0.12017429729380569, 0.6766158217182465,\n",
       "        0.5216043356032593, 0.27487685134180995, 0.7142618448451314,\n",
       "        0.4637221968123332, 0.14388225528808085, -0.0338493768998277,\n",
       "        0.05083339717427893, 0.28824076084608286, 0.004719490961472839,\n",
       "        0.1489209907517438, 0.15507378925542326, 0.9652414094091515,\n",
       "        0.3619561197277851, 0.8012124263723985, 0.08517557028451339,\n",
       "        0.1630903647085562, 0.2584899375606136, 0.1383856233384394,\n",
       "        0.015731658699460693, 0.7143974459896674, 0.2982822319501719,\n",
       "        0.026577916323516915, 0.9419224684023272, 0.39247881985478755,\n",
       "        0.7258799070644816, 0.20823433455485918, 0.07056254336330814,\n",
       "        0.20382054509299508, 0.6981062442228559, 0.3549865906157919,\n",
       "        0.9423125338962189, 0.10818222986093162, 1.0111521383606048,\n",
       "        0.42988298551030807, 0.27258096459451303, 0.09559130598608967,\n",
       "        0.13855336349743974, 0.14976666953735984, 0.8764452052878884,\n",
       "        0.7955212746485609, 0.1895634793584311, 0.0747402760196183,\n",
       "        0.905943830996933, 0.11903522235356034, 0.23496195296914302,\n",
       "        0.14926542899429573, 0.38468862396169934, 0.1440709629669562,\n",
       "        0.65100045750191, 0.7143960369723317, 0.23716161171686623,\n",
       "        0.5981232157506424, 0.8847627751447611, 0.23419583200966532,\n",
       "        0.27145939359371873, 0.2938783132018504, 0.2938783132018504,\n",
       "        0.09604954974018898, 0.48254353548488016, 0.27473870830383895,\n",
       "        0.10147991373934362, 0.10147991373934362, 0.4287255784132059,\n",
       "        0.32784571103733173, 0.8835078407933996, 0.07850830525399466,\n",
       "        0.08540201946877413, 0.15386829387348533, 0.12545849970811462,\n",
       "        0.7786144756082756, 0.427536885949123, 0.17609535357765194,\n",
       "        0.878367307819675, 0.22327057851896914, 0.07416157247106725,\n",
       "        0.12826007748148338, 0.634105869319218, 0.3768260879295245,\n",
       "        0.10151346177114373, 0.3211616974209911, 0.06929198618374022,\n",
       "        0.9052191683494519, 0.09926433462320394, 0.03211007623889506,\n",
       "        0.18986911943336038, 0.847257439169825, 0.16579283274289347,\n",
       "        0.7700327592558944, 0.47082227988701386, 0.7010017615972868,\n",
       "        0.14501818275360545, 0.07989921408122092, 0.12236586720691889,\n",
       "        -0.005626785247986654, 0.6348402921957224, 0.14702226646327232,\n",
       "        0.6215540219710753, 0.15508915425398762, 0.19216345182293582,\n",
       "        0.7453608271264189, 0.192167645326911, 0.8152724924531688,\n",
       "        0.7495897403177768, 0.9591689698511973, 0.42336954566477797,\n",
       "        0.06560674549577605, 0.11783176123759243, 0.11776466517399231,\n",
       "        0.6774028249962442, 0.13103382336414993, 0.21118413561758254,\n",
       "        0.36112866982248604, 0.19216345182293582, 0.32700929830683806,\n",
       "        0.280865751502527, 0.473809463734555, 0.1175480119846275,\n",
       "        0.20818178922700314, 0.8398429556201567, 0.607376016389055,\n",
       "        0.13630879194908085, 0.5713940596353416, 0.23496195296914302,\n",
       "        0.7326641125786182, 0.45892986623510307, 0.2998024855245528,\n",
       "        0.10714485676458663, 0.08545234151647418, 0.3798736277205171,\n",
       "        0.6773091588914584, 0.20818178922700314, 0.8747808191165525,\n",
       "        0.11219476372283887, 0.037110589321790455, 0.2304446210157166,\n",
       "        0.5781125485558966, 0.08803810080323804, 0.43878998795322455,\n",
       "        0.6504786731016186, 0.2521452110239689, 0.0216244599566896,\n",
       "        0.07723566384413616, 0.7649569678355952, 0.10657873372796056,\n",
       "        0.385229660468945, 0.633022282447403, 0.06899188394260825,\n",
       "        0.1924318360773365, 0.08517557028451339, 0.45996376111732684,\n",
       "        0.19216345182293582, 0.7520748407120452, 0.6948104376692462,\n",
       "        0.37454333133827344, 0.14702085744593674, 0.12827403346271216,\n",
       "        0.15490464007908733, 0.8833721428964395, 0.1387149302185282,\n",
       "        0.10142818267430787, 0.06375143929080163, 0.47414353503522,\n",
       "        0.14431837970148165, 0.33220924323584766, 0.9852237367703841,\n",
       "        0.11247224434891612, 0.16013906121224009, 0.026611464355316916,\n",
       "        -0.24136264014289377, 0.10930499702696184, 0.2658827188860972,\n",
       "        0.9347995949199481, 0.06659622240733165, -0.14485706666592768,\n",
       "        0.7321752437264837, 1.0175670238369554, 0.657625381142156,\n",
       "        0.6822749531770065, 0.778507073863936, 0.3066942322964652,\n",
       "        0.7031203811510052, 0.14702085744593674, -0.05351946717403899,\n",
       "        0.2634502073215871, 0.8451989883685845, 0.280865751502527,\n",
       "        0.2885222804534225, 0.7143420826271402, 0.7980685517691132,\n",
       "        0.4057815426662449, 0.10094173621320701, 0.19278936610436637,\n",
       "        0.1121919792361995, 0.8054736415825248, 0.41033242262108166,\n",
       "        -0.0006551458479236993, 0.7893101782796184, 0.7388790838382565,\n",
       "        0.14367398910666607, 0.14968420847519526, 0.10147991373934362,\n",
       "        0.8339629780272846, 0.8065275710028063, 0.07469974999720386,\n",
       "        0.6549652415098843, 0.2679368502547122, 0.11783176123759243,\n",
       "        0.675775470370381, 0.27245418220813866, 0.9991582647944783,\n",
       "        0.587835137141197, 0.48475495643667565, 0.17073932082922405], dtype=object)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the folds returned the probabilty for a different test set, in a different column of the array. But they should be a one dimensional list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = np.concatenate(predictions, axis = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7833894500561167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avanti/anaconda/notebook/src/ipykernel/ipykernel/__main__.py:3: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "predictions[predictions <= 0.5] = 0\n",
    "predictions[predictions > 0.5] = 1\n",
    "accurracy = sum(predictions[predictions == trainframe[\"Survived\"]])/ len(predictions)\n",
    "print(accurracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOt sure why there is such a big difference in the accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7878787878787878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avanti/anaconda/notebook/src/ipykernel/ipykernel/__main__.py:12: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n"
     ]
    }
   ],
   "source": [
    "trainfolds = sklearn.cross_validation.KFold(framesize[0], n_folds = 5, random_state = 1)\n",
    "predictions = []\n",
    "for train, test in trainfolds:\n",
    "    train_predictors = trainframe[predictors].iloc[train, :]\n",
    "    train_survival = trainframe[\"Survived\"].iloc[train]\n",
    "    model.fit(train_predictors, train_survival)\n",
    "    survival = model.predict(trainframe[predictors].iloc[test, :])\n",
    "    predictions.append(survival)\n",
    "predictions = np.concatenate(predictions, axis = 0 )\n",
    "predictions[predictions <= 0.5] = 0\n",
    "predictions[predictions > 0.5] = 1\n",
    "accurracy = sum(predictions[predictions == trainframe[\"Survived\"]])/ len(predictions)\n",
    "print(accurracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
